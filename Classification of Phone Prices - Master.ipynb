{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z9QKjqbzpMhk"
   },
   "source": [
    "###### College of Computing and Digital Media, DePaul University <br>DSC 478: Programming Machine Learning: Spring Quarter 2021<br>Project Type: Analysis<br>Roselyne Tchoua<br>June 11, 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>The Utilization of Machine Learning to Classify Mobile Phone Prices </center><br>\n",
    "### <b><center>By: Dina Allen, Daniel O’Brien, and Cassandra Steffey</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gc_3rmhMpMhl"
   },
   "source": [
    "#### Link to Data Set: \n",
    "https://www.kaggle.com/iabhishekofficial/mobile-price-classification?select=train.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Executive Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background<br>\n",
    "&emsp; The cost of mobile phones is difficult to determine given the varying number of components that go into a mobile phone and the exponential increase in level of technology over the last two decades. Many of the components that deem a phone expensive are hidden features such as RAM. Retail sellers need to understand the complexity of a phone in order to obtain the optimal profit. \n",
    "\n",
    "### Project Goals<br>\n",
    "&emsp; The dataset we will be working with contains sales information about mobile phones. To determine the optimal model to predict the price of a phone, we used clustering methods such as PCA and K-Means as well as classification methods such as KNN, Support Vector Machines, Naive Bayes and Decision Trees.\n",
    "\n",
    "### Contributions<br>\n",
    "&emsp; We distributed work by assigning specific aspects of our analysis to individual members of our team and then came together to discuss and compare our findings. Our main goal was to answer the question of “What is the appropriate price range for a cell phone given its features and components?”. The first step was to perform preprocessing which was completed by Dina Allen. Once pre-processing was completed, Daniel O’Brien performed cluster analysis and Cassandra Steffey performed Principal Component Analysis. Following these initial steps, we met to discuss interesting findings, potential focal points and recommended analysis steps. Following this midpoint discussion, Cassandra Steffey focused on KNN Analysis, Daniel O’Brien worked on a decision tree analysis and Dina Allen constructed a Naive Bayes Classifier and a Support Vector Machine Classifier. We then all worked together to complete the reports and video presentation. \n",
    "\n",
    "### Key Findings<br>\n",
    "<b>Principal Component Analysis (PCA)</b><br>\n",
    "&emsp; After performing data cleaning and preprocessing, Principal Component Analysis was performed to reduce the dimensionality of the data and increase the accuracy of the models. It was found that 99% of the variance in the model could be explained by two principal components. For all model building, the models were performed on three sets of data: the normalized data, one principal component, and two principal components. \n",
    "\n",
    "<b>K Means Clustering</b><br>\n",
    "&emsp; Through analysis of distortion and inertia of the dataset, the optimal number of clusters in the range of 3 to 5 clusters were identified. The best performance was seen with 5 clusters, although overall kMeans returned poor results with each number of clusters. When 5 clusters were applied, the testing data returned a completeness score of 0.22, a homogeneity score of 0.24 and a Mean Silhouette Value of 0.52. Overall, clustering returned a rather poor performance. \n",
    "\n",
    "<b>K - Nearest Neighbors (KNN)</b><br>\n",
    "&emsp; K - Nearest Neighbors was performed on the normalized data and on the principal components found during the principal component analysis. Using grid search, the best parameters for KNN were determined before creating the classifier and calculating the respective metrics. The grid search returned the parameters: n_neighbors = 7 and weights = ‘uniform’). This returned a training accuracy of 0.70 and a testing accuracy of 0.64 on the normalized data. These values do not suggest overfitting but are not ideal for a prediction model. The model using the PCA data performed worse than the normalized data alone.\n",
    "\n",
    "<b>Decision Trees (DT)</b><br>\n",
    "&emsp; Initially the decision tree classification model resulted in overfitting that became apparent with a large difference between training scores (0.99) and testing scores (0.59). To combat this overfitting, the post pruning method of cost complexity pruning was applied. Following cost complexity pruning, a training score of 0.67 and testing score of 0.62 were returned. This is not an ideal performance by decision tree classification, although improvement was seen in the post pruning process.\n",
    "\n",
    "<b>Naive Bayes (NB)</b><br>\n",
    "&emsp; The model when using the full normalized data set and the gaussian distribution resulted in a 53.75% training score and a 55.5% test score. Naive Bayes assumes that predictors are dependent and normally distributed which apparently does not fit well with our model. <br>\n",
    "&emsp; Due to Naive Bayes assumptions that predictors are independent and normally distributed, it struggled to classify test instances accurately. It specifically struggled to classify the third price range category. Of the 53 group 3 records in the test set, only 5 were categorized correctly. This could be a result of being the most expensive price category. Our data pre-processing showed that among the different components in each of the phones, there was not a significant amount of variance between each price category.\n",
    "\n",
    "<b>Support Vector Machines (SVM)</b><br>\n",
    "&emsp; An SVM model was fit to the data in hopes that it would succeed where the Naive Bayes model could not. A focus on finding a curve to differentiate the classes was hypothesized to perform better, but unfortunately it did not. The final model selected used a transformed data set using the first two principal components and anRBF kernel with a C equal to 10 and Gamma equal to .01. It resulted in a 49.75% accuracy.\n",
    "\n",
    "### Conclusions<br>\n",
    "&emsp; The best performing prediction model was the K-Nearest Neighbors Classifier. This model was performed on the normalized data with a n_neighbors of 7 and the weight parameter set to ‘uniform’. These parameters were determined using the grid search method. This model gave a training accuracy of 0.7 and a testing of 0.64 which suggests that the model is not overfitting. The confusion matrix shows that the groups one and three were often misclassified as group two so the model was having difficulty distinguishing these classes. It also shows that the classifier performed best at classifying group zero above the other classes. <br>\n",
    "&emsp; Due to the poor predictability of our models, it would be best for future studies to obtain more data from multiple mobile phone resale stores. The addition of new phone data and updated pricing, the models may be able to classify the different price ranges more accurately.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "doNkxQsHpMhn"
   },
   "source": [
    "## <center>Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4JRKKg-QpMho"
   },
   "source": [
    "### Data Pre-Processing<br>\n",
    "&emsp; Prior to analysis we pre process our data. Steps in pre-processing included checking for missing values, analysis of distribution of the data and normalization. We did not find any missing data values from the dataset. The normalization technique used in our pre-processing stage was z-score normalization. Finally, we split our data into training and testing sets. We set aside 20% of the data to use for testing, while the remaining 80% was used for training.\n",
    "\n",
    "See [Data Pre-Processing](./DataPre-Processing.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "XpcTL_s2pMhp"
   },
   "source": [
    "#### PCA<br>\n",
    "&emsp; After performing data cleaning and preprocessing, Principal Component Analysis was performed to reduce the dimensionality of the data and increase the accuracy of the models. It was found that 99% of the variance in the model could be explained by two principal components. For all model building, the models were performed on three sets of data: the normalized data, one principal component, and two principal components. <br>\n",
    "\n",
    "See [PCA](./PrincipalComponentAnalysis.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5UOLbmVqpMhr"
   },
   "source": [
    "#### Clustering<br>\n",
    "&emsp; Before performing kMeans clustering, an analysis of the distortion and inertia of the dataset and number of clusters was performed to determine the number of ideal clusters. Both the distortion, which measures the averages of the square distances from the cluster centers to the points of the cluster, and the inertia, which measures the sum of the squared distances from each point to their cluster center, indicated that the ideal number of clusters would be somewhere between 3 and 5. <br>\n",
    "&emsp; The best performance by kMeans clustering was with 5 clusters, although overall kMeans returned poor results with each number of clusters. When 5 clusters were applied, the testing data returned a completeness score of 0.22, a homogeneity score of 0.24 and a Mean Silhouette Value of 0.52. The low completeness and homogeneity scores indicate that there were clusters that contained more than one class and that classes were not placed in the same clusters. The Mean Silhouette Value measures the proximity of points within the same cluster and proximity to points of other clusters, the Mean Silhouette Value of 0.52 indicates that some points were far from other points of the same cluster or close to points of other clusters. \n",
    "\n",
    "See [Clustering Notebook](./ClusterProject.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building<br>\n",
    "&emsp; After pre-preocessing our data, each member built classification models. The models include K Nearest Neighbors, Decision Trees, Naive Bayes, and Support Vector Machines. All of the models were built with varying parameters and performed on the normalized data and principal components. The written portion here are the models with the best results per method. To get a more in-depth look into the model building process, please look at the links to each notebook in the respective section. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "STZ4v3eqpMhs"
   },
   "source": [
    "#### KNN<br>\n",
    "&emsp; K - Nearest Neighbors was performed on the normalized data and on the principal components found during the principal component analysis. Using grid search, the best parameters for KNN were determined before creating the classifier and calculating the respective metrics. The grid search returned the parameters: n_neighbors = 7 and weights = ‘uniform’). This returned a training accuracy of 0.70 and a testing accuracy of 0.64 on the normalized data. These values do not suggest overfitting but are not ideal for a prediction model. The model using the PCA data performed worse than the normalized data alone. <br>\n",
    "&emsp; Looking at the outputs, there is a lot of misclassification with group one and group three being labeled as group 2. Also, groups zero and two have many instances where they are predicted as group one. Group zero was predicted the most accurately and group one was predicted the least accurately. Overall, this model did not perform as well as we would like but it did classify certain groups well. \n",
    "\n",
    "See [KNN Notebook](./KNearestNeighbors.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bmWGE2e6pMhs"
   },
   "source": [
    "#### Decision Trees <br>\n",
    "&emsp; Initially the decision tree classifier returned a training score of 0.99 and a testing score of 0.57. This indicates that the decision tree classifier learned the pattern of the training model too closely and thus performed poorly on the testing data. This is a case of overfitting which needs to be addressed by either pre or post pruning the decision tree. Cost complexity pruning was used to address this issue of overfitting. Cost complexity pruning is adjusted by changing the ccp_alpha value for the decision tree classifier. The higher the ccp_alpha value, the more nodes are removed from the decision tree. Analysis was performed examining the impact different ccp_alpha values have on the number of nodes, tree depth and levels of impurity. The final analysis returned a graph examining the accuracy of the training and testing sets and how it corresponds to the different alpha values. <br>\n",
    "&emsp; A ccp_alpha value of 0.01 was selected because it coincided with a peak performance on the testing data and a similar performance on the training data. This indicates that the decision tree model accurately fit the training data and provided a realistic assessment of the testing data. The final performance of the decision tree classifier returned a training accuracy of 0.67 and a testing accuracy of 0.63. This shows slight improvement in the testing accuracy, however this may indicate that a decision tree classifier is not an ideal classification model for this dataset. \n",
    "\n",
    "See [Decision Tree Notebook](./decisiontree.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "USXkrwwNpMht"
   },
   "source": [
    "#### Naive Bayes<br>\n",
    "&emsp; Naives Bayes was performed using the normalized data at the first and second principal components. Multinomial Naive Bayes performed very poorly as did the multinomial and gaussian models when using the principal components. The model when using the full normalized data set and the gaussian distribution resulted in a 53.75% training score and a 55.5% test score. While this is not ideal for a final model, this was the most promising model of the Naive Bayes models that were run. <br>\n",
    "&emsp; Due to Naive Bayes assumptions that predictors are independent and normally distributed, it struggled to classify test instances accurately. Data preprocessing indicated that many of the variables are uniformly distributed which could contribute to why the Naive Bayes model did not perform well. The final model selected specifically struggled to classify the third price range category. Of the 53 group 3 records in the test set, only 5 were categorized correctly. This could be a result of being the most expensive price category. Our data pre-processing showed that among the different components in each of the phones, there was not a significant amount of variance between each price category.\n",
    "\n",
    "See [Naive Bayes and SVM Notebook](./NaiveBayesandSVM.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SBAMIrZ1pMhu"
   },
   "source": [
    "#### Support Vector Machines<br>\n",
    "&emsp; The normalized data and the 2 principal components were used to fit a support vector machine model. Linear and Radial Basis Function(RBF) kernels were used as well as grid search to determine the best selection of C for linear kernels and the best combination of C and Gamma for the RBF kernels. The final model selected used a transformed data set using the first two principal components and anRBF kernel with a C equal to 10 and Gamma equal to .01. It resulted in a 49.75% accuracy. C controls the width of the margin where Gamma controls the size of the radial basis.<br>\n",
    "&emsp; The idea behind testing out an SVM model came because of how poorly Naive Bayes performed. Instead of modeling the distribution of the different classes, it was predicted that maybe finding a curve to separate the different classes would perform better. Unfortunately, this hypothesis was inaccurate and we were not able to create a promising SVM model. \n",
    "\n",
    "See [Naive Bayes and SVM Notebook](./NaiveBayesandSVM.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jwhl3Lr3pMhv"
   },
   "source": [
    "## <center>Conclusion <br>\n",
    "&emsp; Finding an effective and efficient method to accurately predict the price of mobile phones was our objective. Throughout the analysis, we discovered several methods that proved ineffective at meeting our goal. <br>\n",
    "&emsp; The best performing prediction model was the K-Nearest Neighbors Classifier. This model was performed on the normalized data with a n_neighbors of 7 and the weight parameter set to ‘uniform’. These parameters were determined using the grid search method. This model gave a training accuracy of 0.7 and a testing of 0.64 which suggests that the model is not overfitting. The confusion matrix shows that the groups one and three were often misclassified as group two so the model was having difficulty distinguishing these classes. It also shows that the classifier performed best at classifying group zero above the other classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AZbiuJgOpMhv"
   },
   "source": [
    "## <center>Discussion <br>\n",
    "&emsp; While our data set contained 2000 observations, to further our analysis we would like to obtain more data from multiple mobile phone resale stores. With newer phone data and more accurate pricing, that possibly takes consumer demand into account as well, we are hoping to see more variance in the different price range categories. This could potentially help in clustering to determine associated time periods which would be confirmed with a supplemental data set containing mobile phone feature release dates.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ExecutiveSummary.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
